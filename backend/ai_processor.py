import cv2
from PIL import Image, ImageDraw, ImageFont
import numpy as np
from pathlib import Path
import logging
import base64
from io import BytesIO
from typing import Tuple, Optional, Dict, Any
import torch
import urllib.request

from ultralytics.nn.tasks import DetectionModel
from torch.nn.modules.conv import Conv2d
from ultralytics.nn.modules import Detect
from torch.nn.modules.container import Sequential
from ultralytics.nn.modules.conv import Conv, Concat
from torch.nn.modules.batchnorm import BatchNorm2d
from torch.nn.modules.activation import SiLU
from ultralytics.nn.modules.block import C2f
from torch.nn.modules.container import ModuleList
from ultralytics.nn.modules.block import Bottleneck, DFL
from ultralytics.nn.modules.block import SPPF
from torch.nn.modules.pooling import MaxPool2d
from torch.nn.modules.upsampling import Upsample

# –ò–º–ø–æ—Ä—Ç –∏–∑ ultralyticsplus
try:
    from ultralyticsplus import YOLO, load_model
    ULTRALYTICS_PLUS_AVAILABLE = True
except ImportError:
    from ultralytics import YOLO
    ULTRALYTICS_PLUS_AVAILABLE = False
    
torch.serialization.add_safe_globals([DetectionModel, DFL, Concat, Upsample, MaxPool2d, SPPF, Bottleneck, ModuleList, C2f, Conv2d, Detect, Sequential, Conv, BatchNorm2d, SiLU])

log = logging.getLogger(__name__)

class AIPotholeDetector:
    
    DEFAULT_MODEL_ID = "keremberke/yolov8s-pothole-detection"

    LABEL_TRANSLATIONS = {
        'pothole': '–Ø–º–∞',
        'crack': '–¢—Ä–µ—â–∏–Ω–∞',
        'manhole': '–õ—é–∫',
    }

    def __init__(self, model_path: str = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ —è–º.
        
        Args:
            model_path: –ø—É—Ç—å –∫ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏. –ï—Å–ª–∏ None, –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –º–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ HuggingFace.
        """
        try:
            if ULTRALYTICS_PLUS_AVAILABLE:
                if model_path and Path(model_path).exists():
                    self.model = load_model(model_path)
                    log.info(f"‚úÖ –õ–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º ultralyticsplus: {model_path}")
                else:
                    log.info(f"‚ÑπÔ∏è –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ HuggingFace: {self.DEFAULT_MODEL_ID}")
                    self.model = load_model(self.DEFAULT_MODEL_ID)
                    log.info("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ HuggingFace —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º ultralyticsplus")
            else:
                if model_path and Path(model_path).exists():
                    self.model = YOLO(model_path)
                    log.info(f"‚úÖ –õ–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å YOLO –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {model_path}")
                else:
                    self.model = YOLO("best.pt")
                    log.info("‚úÖ –ú–æ–¥–µ–ª—å YOLO –∑–∞–≥—Ä—É–∂–µ–Ω–∞ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —á–∏—Å—Ç–∞—è ultralytics)")
            
            # –ù–ï –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º model.names, —á—Ç–æ–±—ã –Ω–µ —Å–ª–æ–º–∞—Ç—å plot()
            # if hasattr(self.model, 'names'):
            #     ...
            
            # ‚≠ê –ù–û–í–û–ï: –ó–∞–≥—Ä—É–∂–∞–µ–º —à—Ä–∏—Ñ—Ç –¥–ª—è –∫–∏—Ä–∏–ª–ª–∏—Ü—ã
            self.font_path = self._download_cyrillic_font()

        except Exception as e:
            log.exception(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            raise

    def _download_cyrillic_font(self) -> Optional[str]:
        """
        –°–∫–∞—á–∏–≤–∞–µ—Ç —à—Ä–∏—Ñ—Ç —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∫–∏—Ä–∏–ª–ª–∏—Ü—ã –µ—Å–ª–∏ –æ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω.
        
        Returns:
            –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —à—Ä–∏—Ñ—Ç–∞ –∏–ª–∏ None
        """
        font_paths = [
            "/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf",
            "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf",
            "/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf",
            "/System/Library/Fonts/Supplemental/Arial Unicode.ttf",  # macOS
            "C:\\Windows\\Fonts\\arial.ttf",  # Windows
        ]
        
        for font_path in font_paths:
            if Path(font_path).exists():
                log.info(f"‚úÖ –ù–∞–π–¥–µ–Ω —à—Ä–∏—Ñ—Ç: {font_path}")
                return font_path
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–∫–∞—á–∏–≤–∞–µ–º
        fonts_dir = Path("./fonts")
        fonts_dir.mkdir(exist_ok=True)
        font_file = fonts_dir / "DejaVuSans-Bold.ttf"
        
        if not font_file.exists():
            try:
                log.info("üì• –°–∫–∞—á–∏–≤–∞–µ–º —à—Ä–∏—Ñ—Ç DejaVu Sans...")
                url = "https://github.com/dejavu-fonts/dejavu-fonts/raw/master/ttf/DejaVuSans-Bold.ttf"
                urllib.request.urlretrieve(url, str(font_file))
                log.info(f"‚úÖ –®—Ä–∏—Ñ—Ç —Å–∫–∞—á–∞–Ω: {font_file}")
            except Exception as e:
                log.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å —à—Ä–∏—Ñ—Ç: {e}")
                return None
        
        return str(font_file)

    def replace_labels_with_russian(self, annotated_frame: np.ndarray, results) -> np.ndarray:
        """
        ‚≠ê –ö–õ–Æ–ß–ï–í–û–ô –ú–ï–¢–û–î: –ó–∞–º–µ–Ω—è–µ—Ç –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ –º–µ—Ç–∫–∏ –Ω–∞ —Ä—É—Å—Å–∫–∏–µ –≤ —É–∂–µ –æ—Ç—Ä–∏—Å–æ–≤–∞–Ω–Ω–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏.
        –¢–µ–∫—Å—Ç –ë–ï–ó —Ñ–æ–Ω–∞, —Ç–æ–ª—å–∫–æ —Å —Ç–µ–Ω—å—é –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏.
        
        Args:
            annotated_frame: –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –æ—Ç—Ä–∏—Å–æ–≤–∞–Ω–Ω—ã–º–∏ bbox –æ—Ç YOLO (BGR)
            results: —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–µ—Ç–µ–∫—Ü–∏–∏
            
        Returns:
            –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å —Ä—É—Å—Å–∫–∏–º–∏ –º–µ—Ç–∫–∞–º–∏ (BGR)
        """
        if not self.font_path:
            log.warning("‚ö†Ô∏è –®—Ä–∏—Ñ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π")
            return annotated_frame
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ RGB –¥–ª—è PIL
        image_rgb = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)
        pil_image = Image.fromarray(image_rgb)
        draw = ImageDraw.Draw(pil_image)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —à—Ä–∏—Ñ—Ç
        try:
            font = ImageFont.truetype(self.font_path, 24)  # –†–∞–∑–º–µ—Ä —à—Ä–∏—Ñ—Ç–∞
        except Exception as e:
            log.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —à—Ä–∏—Ñ—Ç: {e}")
            return annotated_frame
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é –¥–µ—Ç–µ–∫—Ü–∏—é
        for result in results:
            if result.boxes is not None:
                for box in result.boxes:
                    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ
                    x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())
                    confidence = box.conf[0].item()
                    class_id = int(box.cls[0].item())
                    
                    # –ü–æ–ª—É—á–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–º—è –∫–ª–∞—Å—Å–∞
                    class_name = self.model.names.get(class_id, "unknown")
                    
                    # ‚≠ê –ü–µ—Ä–µ–≤–æ–¥–∏–º –Ω–∞ —Ä—É—Å—Å–∫–∏–π
                    russian_label = self.LABEL_TRANSLATIONS.get(class_name, class_name)
                    
                    # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç
                    text = f"{russian_label}"
                    
                    # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä —Ç–µ–∫—Å—Ç–∞
                    bbox = draw.textbbox((0, 0), text, font=font)
                    text_width = bbox[2] - bbox[0]
                    text_height = bbox[3] - bbox[1]
                    
                    # –ü–æ–∑–∏—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ (–Ω–∞–¥ bbox)
                    text_x = x1 + 5
                    text_y = y1 - text_height - 10
                    
                    # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –≤—ã—Ö–æ–¥–∏—Ç –∑–∞ –≤–µ—Ä—Ö–Ω—é—é –≥—Ä–∞–Ω–∏—Ü—É, –ø–æ–º–µ—â–∞–µ–º –≤–Ω—É—Ç—Ä—å bbox
                    if text_y < 0:
                        text_y = y1 + 5
                    
                    # ‚≠ê –†–∏—Å—É–µ–º —Ç–µ–Ω—å (—á–µ—Ä–Ω—ã–π —Ç–µ–∫—Å—Ç —Å–æ —Å–º–µ—â–µ–Ω–∏–µ–º)
                    shadow_offset = 2
                    draw.text(
                        (text_x + shadow_offset, text_y + shadow_offset),
                        text,
                        fill=(0, 0, 0),  # –ß–µ—Ä–Ω–∞—è —Ç–µ–Ω—å
                        font=font
                    )
                    
                    # ‚≠ê –†–∏—Å—É–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç (–±–µ–ª—ã–π)
                    draw.text(
                        (text_x, text_y),
                        text,
                        fill=(255, 255, 255),  # –ë–µ–ª—ã–π —Ç–µ–∫—Å—Ç
                        font=font
                    )
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ BGR
        result_bgr = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
        return result_bgr


    def detect_potholes(
        self, 
        image_path: str,
        annotation_quality: int = 98,
        use_russian_labels: bool = True
    ) -> Tuple[bool, float, str, Optional[str]]:
        """
        –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —è–º –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏.
        """
        try:
            # –ó–∞–ø—É—Å–∫ –¥–µ—Ç–µ–∫—Ü–∏–∏
            results = self.model.predict(image_path)
            
            has_problem = False
            max_confidence = 0.0
            category = "unknown"
            num_detections = 0
            
            # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            for result in results:
                if result.boxes is not None and len(result.boxes) > 0:
                    has_problem = True
                    num_detections = len(result.boxes)
                    
                    for box in result.boxes:
                        confidence = box.conf[0].item()
                        if confidence > max_confidence:
                            max_confidence = confidence
                    
                    if num_detections >= 3:
                        category = "multiple_potholes"
                    elif max_confidence > 0.8:
                        category = "pothole"
                    else:
                        category = "possible_pothole"
            
            # –°–æ–∑–¥–∞–µ–º –∞–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            annotated_image_base64 = None
            if has_problem and len(results) > 0:
                # ‚≠ê –ù–û–í–û–ï: –û—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ–º –ë–ï–ó –º–µ—Ç–æ–∫ (—Ç–æ–ª—å–∫–æ bbox)
                annotated_frame = results[0].plot(
                    labels=False,  # ‚≠ê –û—Ç–∫–ª—é—á–∞–µ–º –º–µ—Ç–∫–∏!
                    conf=False,    # ‚≠ê –û—Ç–∫–ª—é—á–∞–µ–º confidence!
                    line_width=1,  # –¢–æ–ª—â–∏–Ω–∞ –ª–∏–Ω–∏–π bbox
                    boxes=True     # –û—Å—Ç–∞–≤–ª—è–µ–º bbox
                )
                
                # ‚≠ê –î–æ–±–∞–≤–ª—è–µ–º —Ä—É—Å—Å–∫–∏–µ –º–µ—Ç–∫–∏
                if use_russian_labels:
                    annotated_frame = self.replace_labels_with_russian(annotated_frame, results)
                
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ RGB –¥–ª—è PIL
                annotated_frame_rgb = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)
                pil_image = Image.fromarray(annotated_frame_rgb)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å –≤—ã—Å–æ–∫–∏–º –∫–∞—á–µ—Å—Ç–≤–æ–º
                buffered = BytesIO()
                pil_image.save(
                    buffered, 
                    format="JPEG", 
                    quality=annotation_quality,
                    optimize=False,
                    subsampling=0
                )
                annotated_image_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')
                
                log.info(f"‚úÖ –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {num_detections} —è–º —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é {max_confidence:.2f}")
                log.info(f"üìä –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {len(buffered.getvalue()) / 1024:.2f} KB")
            else:
                # –ï—Å–ª–∏ –ø—Ä–æ–±–ª–µ–º –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                original_image = Image.open(image_path)
                buffered = BytesIO()
                original_image.save(
                    buffered, 
                    format="JPEG", 
                    quality=annotation_quality,
                    optimize=False,
                    subsampling=0
                )
                annotated_image_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')
                log.info("‚ÑπÔ∏è –ü—Ä–æ–±–ª–µ–º—ã –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã")
            
            return has_problem, max_confidence, category, annotated_image_base64
            
        except Exception as e:
            log.exception(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
            return False, 0.0, "error", None


    def get_detection_details(self, image_path: str) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è—Ö.
        
        Args:
            image_path: –ø—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é.
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π.
        """
        try:
            results = self.model.predict(image_path)
            
            detections = []
            for result in results:
                if result.boxes is not None:
                    for i, box in enumerate(result.boxes):
                        detection = {
                            "id": i + 1,
                            "confidence": box.conf[0].item(),
                            "bbox": box.xyxy[0].tolist(),
                            "area": float((box.xyxy[0][2] - box.xyxy[0][0]) * (box.xyxy[0][3] - box.xyxy[0][1]))
                        }
                        detections.append(detection)
            
            detections.sort(key=lambda x: x["confidence"], reverse=True)
            
            severity = "none"
            if detections:
                total_area = sum(d["area"] for d in detections)
                if len(detections) >= 5 or total_area > 50000:
                    severity = "critical"
                elif len(detections) >= 3 or total_area > 20000:
                    severity = "high"
                elif len(detections) >= 1:
                    severity = "medium"
            
            return {
                "detections": detections,
                "total_count": len(detections),
                "severity": severity,
                "avg_confidence": np.mean([d["confidence"] for d in detections]) if detections else 0
            }
            
        except Exception as e:
            log.exception(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–µ—Ç–∞–ª–µ–π: {e}")
            return {
                "detections": [],
                "total_count": 0,
                "severity": "error",
                "avg_confidence": 0
            }

_detector = None

def get_ai_detector(model_path: str = None):
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–∏–Ω–≥–ª—Ç–æ–Ω–∞ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞.
    """
    global _detector
    if _detector is None:
        _detector = AIPotholeDetector(model_path)
    return _detector